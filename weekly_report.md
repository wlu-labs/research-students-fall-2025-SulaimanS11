## Weekly Report
- This file contains a paragraph of 1000 Characters or more about the progress made by the student for each week. I am creating the place holder for it.

### Week 1 (Date: Sept 8 - 12   )
This week, my primary focus was on foundational research and project scoping. Following a meeting with the Digital Twin team on Wednesday, I chose the project I will be working on for the duration of this research study: enhancing the scalability of the DTUMOS platform through multi-threaded programming. This project aims to address the limitations of the current DTUMOS architecture by investigating and implementing multiprocessing or compiled extensions to improve the performance and scalability of CPU-bound simulations. To build a strong knowledge base for this work, I conducted my literature review. I analyzed three key papers. The first, "DTUMOS, digital twin for large-scale urban mobility operating system," served as a direct reference, detailing the current architecture and scalability challenges I will be addressing. The second paper, "The path to medical superintelligence" by Microsoft AI, though in a different domain, provided insight into benchmarking large-scale AI systems, which will inform how I measure the performance gains of my solution. The third paper, "TransETA: transformer networks for estimated time of arrival with local congestion representation," was crucial for understanding deep learning models for complex traffic simulations and highlighted the importance of computational efficiency. In a subsequent meeting, Mr. Sehra directed me to focus my initial research on core concepts like parallel processing, Python programming for multi-threaded applications, and thread-level processing. These topics will form the basis of my next steps as I transition from research to practical implementation. My work this week has successfully established a clear project direction and a strong theoretical foundation.

### Week 2 (Date: Sept 15 - 19  )
This week, I continued my foundational research, with a specific focus on the core technical concepts that will underpin my project. I conducted review and research on parallel processing and multi-threaded programming, delving into how these techniques can be applied to enhance the performance of CPU-bound simulations. I also expanded my literature review to include research on optimizing DTUMOS, with attention to Estimated Time of Arrival (ETA) models. My research this week has been crucial for building a strong theoretical framework before I transition to practical implementation and codebase analysis. The knowledge I've gained will directly inform my approach to optimizing DTUMOS for improved scalability.

### Week 3 (Date: Sept 22 - 26  )
This week, I shifted my focus from a broad literature review to a more practical analysis of the project. My primary accomplishment was completing a thorough review of the DTUMOS codebase. This deep dive was critical for identifying potential areas for optimization and understanding the existing architecture's limitations. Concurrently, I continued to refine my research into optimization strategies, multi-threaded programming, and parallel processing. This dual-pronged approach of hands-on code analysis and theoretical research has provided me with a clear roadmap for the next phase of my project, allowing me to pinpoint specific sections of the code that can benefit from performance enhancements. My work this week has successfully bridged the gap between foundational knowledge and practical application.

### Week 4 (Date: Sept 29 - Oct 3  )
This week was  productive, I focused on detailed codebase analysis and strategic planning for the optimization phase. I familiarized myself with the complete DTUMOS codebase and made significant progress in detailing the time complexity of its core files. By the end of the week, I only had one and a half files remaining for time analysis documentation, which I aim to complete today.

Key strategic developments occurred during our meetings:
- Wednesday Meeting: We discussed and decided to investigate specialized software tools capable of measuring the load and performance of various files and processes within the codebase. This will complement the static time complexity analysis with dynamic profiling data.
- Thursday Meeting: I received guidance from Dr. Jiho, who advised me to consider using Rust to rewrite specific performance-critical functions. This approach, alongside the planned implementation of multi-threading and parallel processing, will be a core strategy for achieving significant performance and scalability improvements in DTUMOS.

My work this week has solidified the technical direction of the project, moving from analysis into concrete optimization planning.

### Week 5 (Date: Oct 6 - 10))
This week marked the completion of the foundational static analysis and the transition to preparing for dynamic analysis. I successfully finished the time complexity analysis for the remaining files in the DTUMOS codebase and ensured the platform was fully set up to run on my system. Along with that, I began refamiliarizing myself with the fundamentals of Rust and best practices for parallel processing, following the guidance received last week.

During the Wednesday meeting, Dr. Sehra advised that a dynamic analysis of the system—specifically, measuring which functions are called and how often—would be an invaluable asset for precisely identifying performance bottlenecks. I dedicated the latter half of the week to designing and structuring the implementation plan for this dynamic profiling. This includes determining whether to go with a tool or a script I create that would outline the required code structure and capture runtime frequency and load data. By the end of the week, I had the first version of the analysis script ready to run a dynamic analysis of DTUMOS. This dynamic data will be crucial for validating my static analysis and directing the subsequent optimization efforts.

### Week 6 (Date: Date: Oct 13 - 17  )
This week, coinciding with the mid-semester break, was dedicated to refining the tools necessary for the upcoming dynamic analysis phase. I focused on revising the dynamic function count analysis script that I had designed the previous week. I aimed to ensure the script was robust and ready for deployment. However, I encountered a significant technical roadblock: my local machine proved to be too underpowered to run the DTUMOS simulation in any reasonable amount of time. This limitation prevents me from performing the crucial dynamic profiling on my current setup, necessitating a shift in the plan to utilize a more powerful resource (e.g., cloud computing or a dedicated lab machine) for the next phase of work.
